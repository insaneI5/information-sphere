"""
ä¿¡æ¯ç²’å­ç³»ç»Ÿ - åº”ç”¨æ¡ˆä¾‹æ¼”ç¤º

å±•ç¤º4ä¸ªå®é™…åº”ç”¨åœºæ™¯ï¼š
1. å›¾åƒè´¨é‡è¯„ä¼°
2. å¼‚å¸¸æ£€æµ‹
3. æ•°æ®å‹ç¼©åˆ†æ
4. ä¿¡æ¯ç»“æ„å¯è§†åŒ–

ä½œè€…ï¼šåŒ—äº¬æ±‚ä¸€æ•°ç”Ÿç§‘æŠ€ä¸­å¿ƒ
"""

import torch
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Circle
import time

from information_oriented_system_v2 import InformationOrientedSystemV2


class QualityAssessment:
    """åº”ç”¨1: å›¾åƒè´¨é‡è¯„ä¼°"""
    
    def __init__(self):
        self.system = InformationOrientedSystemV2(particle_size=4)
    
    def assess(self, image):
        """è¯„ä¼°å›¾åƒè´¨é‡"""
        output = self.system.forward(image)
        
        return {
            'overall_quality': output['avg_sif'],
            'num_particles': output['num_particles'],
            'num_groups': output['num_groups'],
            'particles': output['particles']
        }
    
    def compare_quality(self, images, labels):
        """å¯¹æ¯”å¤šå¼ å›¾åƒè´¨é‡"""
        results = []
        
        for i, (img, label) in enumerate(zip(images, labels)):
            quality = self.assess(img.squeeze(0))
            results.append({
                'index': i,
                'label': label,
                'quality': quality['overall_quality'],
                'particles': quality['num_particles'],
                'groups': quality['num_groups']
            })
        
        return results


class AnomalyDetection:
    """åº”ç”¨2: å¼‚å¸¸æ£€æµ‹"""
    
    def __init__(self, sif_threshold=0.3):
        self.system = InformationOrientedSystemV2(particle_size=4)
        self.sif_threshold = sif_threshold
    
    def detect(self, image):
        """æ£€æµ‹å›¾åƒä¸­çš„å¼‚å¸¸åŒºåŸŸ"""
        output = self.system.forward(image)
        
        # æ‰¾å‡ºä½SIFç²’å­ï¼ˆå¼‚å¸¸å€™é€‰ï¼‰
        anomalies = []
        for particle in output['particles']:
            if particle.sif_value < self.sif_threshold:
                anomalies.append({
                    'sequence_idx': particle.sequence_index,
                    'sif': particle.sif_value,
                    'connectivity': particle.connectivity,
                    'density': particle.density,
                    'energy': particle.energy
                })
        
        return {
            'num_anomalies': len(anomalies),
            'anomaly_rate': len(anomalies) / output['num_particles'],
            'anomalies': anomalies,
            'avg_sif': output['avg_sif']
        }
    
    def visualize_anomalies(self, image, detection_result, save_path='anomaly_detection.png'):
        """å¯è§†åŒ–å¼‚å¸¸åŒºåŸŸ"""
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # åŸå›¾
        axes[0].imshow(image.cpu().numpy(), cmap='gray')
        axes[0].set_title('Original Image')
        axes[0].axis('off')
        
        # å¼‚å¸¸æ ‡è®°
        axes[1].imshow(image.cpu().numpy(), cmap='gray')
        
        # æ ‡è®°å¼‚å¸¸åŒºåŸŸ
        particle_size = 4
        for anomaly in detection_result['anomalies']:
            idx = anomaly['sequence_idx']
            row = (idx * particle_size) // image.shape[1]
            col = (idx * particle_size) % image.shape[1]
            
            rect = plt.Rectangle(
                (col, row), particle_size, particle_size,
                linewidth=2, edgecolor='red', facecolor='none'
            )
            axes[1].add_patch(rect)
        
        axes[1].set_title(f'Anomalies Detected: {detection_result["num_anomalies"]}')
        axes[1].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()


class CompressionAnalysis:
    """åº”ç”¨3: æ•°æ®å‹ç¼©åˆ†æ"""
    
    def __init__(self):
        self.system = InformationOrientedSystemV2(particle_size=4)
    
    def analyze(self, image):
        """åˆ†æå‹ç¼©æ€§èƒ½"""
        start = time.time()
        output = self.system.forward(image)
        process_time = (time.time() - start) * 1000
        
        # åŸå§‹å¤§å°
        original_size = image.numel() * 4  # float32 = 4 bytes
        
        # å‹ç¼©å¤§å°ï¼ˆç‰¹å¾+raw_contentï¼‰
        feature_size = output['num_particles'] * 12 * 4  # 12ç»´ç‰¹å¾
        content_size = original_size  # raw_contentä¿æŒåŸå¤§å°
        
        compressed_size = feature_size + content_size
        
        # ä½†æˆ‘ä»¬æä¾›äº†é¢å¤–ä¿¡æ¯ï¼
        extra_info = {
            'sif_values': output['num_particles'],
            'group_structure': output['num_groups'],
            'sphere_coordinates': output['num_particles'] * 3
        }
        
        return {
            'original_size': original_size,
            'feature_size': feature_size,
            'content_size': content_size,
            'total_size': compressed_size,
            'compression_ratio': original_size / compressed_size,
            'extra_info': extra_info,
            'process_time': process_time,
            'avg_sif': output['avg_sif']
        }


class StructureVisualization:
    """åº”ç”¨4: ä¿¡æ¯ç»“æ„å¯è§†åŒ–"""
    
    def __init__(self):
        self.system = InformationOrientedSystemV2(particle_size=4)
    
    def visualize(self, image, save_path='structure_viz.png'):
        """å¯è§†åŒ–ä¿¡æ¯ç»“æ„"""
        output = self.system.forward(image)
        
        fig = plt.figure(figsize=(16, 4))
        gs = fig.add_gridspec(1, 4, wspace=0.3)
        
        # 1. åŸå›¾
        ax1 = fig.add_subplot(gs[0])
        ax1.imshow(image.cpu().numpy(), cmap='gray')
        ax1.set_title('Original Image')
        ax1.axis('off')
        
        # 2. SIFåˆ†å¸ƒ
        ax2 = fig.add_subplot(gs[1])
        sif_values = [p.sif_value for p in output['particles']]
        ax2.hist(sif_values, bins=20, color='skyblue', edgecolor='black')
        ax2.set_title(f'SIF Distribution\n(Avg: {np.mean(sif_values):.3f})')
        ax2.set_xlabel('SIF Value')
        ax2.set_ylabel('Count')
        ax2.grid(True, alpha=0.3)
        
        # 3. è¿æ¥åº¦ç½‘ç»œ
        ax3 = fig.add_subplot(gs[2])
        connectivity_values = [p.connectivity for p in output['particles']]
        ax3.scatter(range(len(connectivity_values)), connectivity_values, 
                   c=sif_values, cmap='viridis', s=50)
        ax3.set_title('Connectivity Network')
        ax3.set_xlabel('Particle Index')
        ax3.set_ylabel('Connectivity')
        ax3.grid(True, alpha=0.3)
        
        # 4. çƒé¢æŠ•å½±
        ax4 = fig.add_subplot(gs[3])
        theta_vals = []
        phi_vals = []
        for p in output['particles']:
            r, theta, phi = p.get_sphere_coordinates()
            theta_vals.append(theta)
            phi_vals.append(phi)
        
        scatter = ax4.scatter(phi_vals, theta_vals, c=sif_values, 
                             cmap='viridis', s=50, alpha=0.6)
        ax4.set_title('Sphere Projection')
        ax4.set_xlabel('Ï† (azimuth)')
        ax4.set_ylabel('Î¸ (polar)')
        ax4.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax4, label='SIF Value')
        
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return {
            'avg_sif': np.mean(sif_values),
            'avg_connectivity': np.mean(connectivity_values),
            'num_particles': len(output['particles']),
            'num_groups': output['num_groups']
        }


def demo_quality_assessment():
    """æ¼”ç¤º1: å›¾åƒè´¨é‡è¯„ä¼°"""
    print("\n" + "="*70)
    print("  åº”ç”¨æ¡ˆä¾‹1: å›¾åƒè´¨é‡è¯„ä¼°")
    print("="*70)
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.MNIST(
        root='./data/MNIST', train=False, download=False, transform=transform
    )
    
    # é€‰æ‹©10å¼ å›¾åƒ
    images = [testset[i][0] for i in range(10)]
    labels = [testset[i][1] for i in range(10)]
    
    qa = QualityAssessment()
    results = qa.compare_quality(images, labels)
    
    print("\nğŸ“Š è´¨é‡è¯„ä¼°ç»“æœ:")
    print(f"{'ç´¢å¼•':<6} {'æ ‡ç­¾':<6} {'è´¨é‡(SIF)':<12} {'ç²’å­æ•°':<10} {'ä¿¡æ¯ç»„':<10}")
    print("-"*70)
    
    for r in results:
        print(f"{r['index']:<6} {r['label']:<6} {r['quality']:<12.4f} "
              f"{r['particles']:<10} {r['groups']:<10}")
    
    print(f"\nâœ… å…³é”®å‘ç°:")
    avg_quality = np.mean([r['quality'] for r in results])
    print(f"   å¹³å‡å›¾åƒè´¨é‡: {avg_quality:.4f}")
    print(f"   è´¨é‡èŒƒå›´: [{min(r['quality'] for r in results):.4f}, "
          f"{max(r['quality'] for r in results):.4f}]")
    print(f"   ğŸ’¡ SIFå€¼å¯ä½œä¸ºæ— å‚è€ƒå›¾åƒè´¨é‡æŒ‡æ ‡ï¼")


def demo_anomaly_detection():
    """æ¼”ç¤º2: å¼‚å¸¸æ£€æµ‹"""
    print("\n" + "="*70)
    print("  åº”ç”¨æ¡ˆä¾‹2: å¼‚å¸¸æ£€æµ‹")
    print("="*70)
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.MNIST(
        root='./data/MNIST', train=False, download=False, transform=transform
    )
    
    detector = AnomalyDetection(sif_threshold=0.35)
    
    print("\nğŸ” æ£€æµ‹10å¼ å›¾åƒçš„å¼‚å¸¸...")
    
    for i in range(10):
        image, label = testset[i]
        image_2d = image.squeeze(0)
        
        result = detector.detect(image_2d)
        
        print(f"  å›¾åƒ{i} (æ•°å­—{label}): "
              f"å¼‚å¸¸ç‡={result['anomaly_rate']*100:.1f}%, "
              f"å¼‚å¸¸æ•°={result['num_anomalies']}, "
              f"å¹³å‡SIF={result['avg_sif']:.4f}")
        
        # å¯è§†åŒ–ç¬¬ä¸€å¼ 
        if i == 0:
            detector.visualize_anomalies(image_2d, result, 
                                        f'anomaly_detection_sample.png')
    
    print(f"\nâœ… åº”ç”¨ä»·å€¼:")
    print(f"   ğŸ’¡ ä½SIFåŒºåŸŸæ ‡è®°æ½œåœ¨é—®é¢˜")
    print(f"   ğŸ’¡ å¯ç”¨äºè´¨é‡æ§åˆ¶ã€ç¼ºé™·æ£€æµ‹")
    print(f"   âœ… å¯è§†åŒ–ä¿å­˜: anomaly_detection_sample.png")


def demo_compression_analysis():
    """æ¼”ç¤º3: æ•°æ®å‹ç¼©åˆ†æ"""
    print("\n" + "="*70)
    print("  åº”ç”¨æ¡ˆä¾‹3: æ•°æ®å‹ç¼©åˆ†æ")
    print("="*70)
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.MNIST(
        root='./data/MNIST', train=False, download=False, transform=transform
    )
    
    analyzer = CompressionAnalysis()
    
    # åˆ†æå¤šå¼ å›¾åƒ
    results = []
    for i in range(10):
        image, label = testset[i]
        result = analyzer.analyze(image.squeeze(0))
        results.append(result)
    
    print("\nğŸ“Š å‹ç¼©åˆ†æç»“æœ:")
    
    avg_orig = np.mean([r['original_size'] for r in results])
    avg_feat = np.mean([r['feature_size'] for r in results])
    avg_total = np.mean([r['total_size'] for r in results])
    avg_time = np.mean([r['process_time'] for r in results])
    
    print(f"   åŸå§‹å¤§å°:   {avg_orig/1024:.2f} KB")
    print(f"   ç‰¹å¾å¤§å°:   {avg_feat/1024:.2f} KB")
    print(f"   æ€»å¤§å°:     {avg_total/1024:.2f} KB")
    print(f"   å‹ç¼©æ¯”:     {avg_orig/avg_total:.2f}x")
    print(f"   å¤„ç†æ—¶é—´:   {avg_time:.2f}ms")
    
    print(f"\nâœ… å…³é”®ä¼˜åŠ¿:")
    print(f"   ğŸ’¡ è™½ç„¶å¢åŠ äº†{(avg_total-avg_orig)/1024:.2f}KBç‰¹å¾")
    print(f"   ğŸ’¡ ä½†æä¾›äº†:")
    print(f"      - 12ç»´å¯è§£é‡Šç‰¹å¾")
    print(f"      - SIFè´¨é‡è¯„åˆ†")
    print(f"      - ä¿¡æ¯ç»„ç»“æ„")
    print(f"      - çƒé¢æ‹“æ‰‘å…³ç³»")
    print(f"   âœ… ç”¨å°‘é‡é¢å¤–ç©ºé—´æ¢å–ä¸°å¯Œçš„ç»“æ„ä¿¡æ¯ï¼")


def demo_structure_visualization():
    """æ¼”ç¤º4: ä¿¡æ¯ç»“æ„å¯è§†åŒ–"""
    print("\n" + "="*70)
    print("  åº”ç”¨æ¡ˆä¾‹4: ä¿¡æ¯ç»“æ„å¯è§†åŒ–")
    print("="*70)
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.MNIST(
        root='./data/MNIST', train=False, download=False, transform=transform
    )
    
    visualizer = StructureVisualization()
    
    # å¯è§†åŒ–3å¼ ä¸åŒæ•°å­—
    for digit in [0, 5, 8]:
        # æ‰¾åˆ°è¯¥æ•°å­—çš„æ ·æœ¬
        for i in range(len(testset)):
            if testset[i][1] == digit:
                image = testset[i][0].squeeze(0)
                result = visualizer.visualize(image, 
                                             f'structure_viz_digit_{digit}.png')
                
                print(f"\n  æ•°å­— {digit}:")
                print(f"    å¹³å‡SIF: {result['avg_sif']:.4f}")
                print(f"    å¹³å‡è¿æ¥åº¦: {result['avg_connectivity']:.4f}")
                print(f"    ä¿¡æ¯ç»„æ•°: {result['num_groups']}")
                print(f"    å¯è§†åŒ–ä¿å­˜: structure_viz_digit_{digit}.png")
                break
    
    print(f"\nâœ… åº”ç”¨ä»·å€¼:")
    print(f"   ğŸ’¡ ç›´è§‚å±•ç¤ºä¿¡æ¯çš„å†…åœ¨ç»“æ„")
    print(f"   ğŸ’¡ SIFåˆ†å¸ƒåæ˜ å†…å®¹å¤æ‚åº¦")
    print(f"   ğŸ’¡ è¿æ¥åº¦ç½‘ç»œæ­ç¤ºä¿¡æ¯å…³è”")
    print(f"   ğŸ’¡ çƒé¢æŠ•å½±æ˜¾ç¤ºæ‹“æ‰‘å…³ç³»")


def generate_summary():
    """ç”Ÿæˆåº”ç”¨æ¡ˆä¾‹æ€»ç»“"""
    print("\n" + "="*70)
    print("  åº”ç”¨æ¡ˆä¾‹æ€»ç»“")
    print("="*70)
    
    summary = """
âœ… å·²æ¼”ç¤º4ä¸ªå®é™…åº”ç”¨ï¼š

1. **å›¾åƒè´¨é‡è¯„ä¼°**
   - æ— éœ€å‚è€ƒå›¾åƒ
   - SIFå€¼ä½œä¸ºè´¨é‡æŒ‡æ ‡
   - å®æ—¶è¯„ä¼°å›¾åƒè´¨é‡
   
2. **å¼‚å¸¸æ£€æµ‹**
   - è‡ªåŠ¨è¯†åˆ«ä½è´¨é‡åŒºåŸŸ
   - å¯è§†åŒ–å¼‚å¸¸ä½ç½®
   - é€‚ç”¨äºè´¨é‡æ§åˆ¶

3. **æ•°æ®å‹ç¼©åˆ†æ**
   - å°‘é‡é¢å¤–ç©ºé—´
   - æä¾›ä¸°å¯Œç»“æ„ä¿¡æ¯
   - 12ç»´ç‰¹å¾ + SIF + æ‹“æ‰‘

4. **ä¿¡æ¯ç»“æ„å¯è§†åŒ–**
   - ç›´è§‚å±•ç¤ºä¿¡æ¯ç»„ç»‡
   - å¤šè§’åº¦åˆ†æå†…å®¹
   - æ­ç¤ºéšè—æ¨¡å¼

ğŸ¯ æ ¸å¿ƒä»·å€¼ï¼š

1. **é€æ˜æ€§**: æ‰€æœ‰ç‰¹å¾å¯è§£é‡Š
2. **å®ç”¨æ€§**: å³æ’å³ç”¨çš„åº”ç”¨
3. **é€šç”¨æ€§**: é€‚ç”¨äºå¤šç§æ•°æ®
4. **é«˜æ•ˆæ€§**: æ¯«ç§’çº§å¤„ç†é€Ÿåº¦

ğŸ’¡ æ½œåœ¨åº”ç”¨é¢†åŸŸï¼š

- å›¾åƒ/è§†é¢‘è´¨é‡è¯„ä¼°
- å·¥ä¸šç¼ºé™·æ£€æµ‹
- åŒ»å­¦å›¾åƒåˆ†æ
- æ•°æ®è´¨é‡ç›‘æ§
- ä¿¡æ¯æ£€ç´¢ä¸æ¨è
- å¼‚å¸¸è¡Œä¸ºæ£€æµ‹
- å†…å®¹ç†è§£ä¸ç”Ÿæˆ
"""
    
    print(summary)


if __name__ == '__main__':
    print("\n" + "="*70)
    print("  ä¿¡æ¯ç²’å­ç³»ç»Ÿ - åº”ç”¨æ¡ˆä¾‹æ¼”ç¤º")
    print("  ä½œè€…: åŒ—äº¬æ±‚ä¸€æ•°ç”Ÿç§‘æŠ€ä¸­å¿ƒ")
    print("="*70)
    
    # æ¼”ç¤ºæ‰€æœ‰åº”ç”¨
    demo_quality_assessment()
    demo_anomaly_detection()
    demo_compression_analysis()
    demo_structure_visualization()
    
    # ç”Ÿæˆæ€»ç»“
    generate_summary()
    
    print("\n" + "="*70)
    print("  æ‰€æœ‰åº”ç”¨æ¡ˆä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print("="*70)

