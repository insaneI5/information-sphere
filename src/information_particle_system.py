"""
ä¿¡æ¯ç²’å­ç³»ç»Ÿ - Information Particle System

æ ¸å¿ƒç†å¿µï¼šä¿¡æ¯ç²’å­åŒ–ï¼ˆç±»ä¼¼åƒç´ ç‚¹ï¼‰
- ä¿¡æ¯å…ƒ = ä¿¡æ¯çš„æœ€å°å•å…ƒï¼ˆç²’å­/åƒç´ ç‚¹ï¼‰
- 12ç»´ç‰¹å¾ç»“æ„ï¼ˆå€Ÿé‰´æ—¶é—´é›†ç»´åº¦ç³»ç»Ÿè®¾è®¡ï¼‰
- çº¯æ•°å­¦æ–¹æ³•ï¼ˆæ— ç¥ç»ç½‘ç»œï¼‰
- å®Œå…¨é€æ˜å¯è§£é‡Š

ç†è®ºåŸºç¡€ï¼š
1. ä¿¡æ¯ç²’å­åŒ–ï¼šå°†è¿ç»­æ•°æ®ç¦»æ•£åŒ–ä¸ºç‹¬ç«‹çš„ä¿¡æ¯å•å…ƒ
2. äº”ç»´è®¤çŸ¥æ¡†æ¶ï¼šç‚¹â†’é¢â†’ç«‹ä½“â†’æ—¶é—´â†’æ—¶é—´é›†
3. SIFå€¼ï¼šStructure-Information-Functionï¼ˆç»“æ„-ä¿¡æ¯-åŠŸèƒ½ï¼‰

ä½œè€…ï¼šåŒ—äº¬æ±‚ä¸€æ•°ç”Ÿç§‘æŠ€ä¸­å¿ƒ
ç‰ˆæœ¬ï¼š2.0.0 (ç†è®ºé‡æ„ç‰ˆ)
"""

import torch
import torch.nn.functional as F
import numpy as np
import time
import math
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass


@dataclass
class InformationParticle:
    """
    ä¿¡æ¯ç²’å­ - ä¿¡æ¯çš„æœ€å°å•å…ƒï¼ˆåƒç´ ç‚¹ï¼‰
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - æ¯ä¸ªç²’å­æ˜¯ä¿¡æ¯çš„åŸºæœ¬å•å…ƒï¼Œç±»ä¼¼å›¾åƒçš„åƒç´ ç‚¹
    - æœ‰æ˜ç¡®çš„12ç»´ç‰¹å¾æè¿°å…¶å±æ€§
    - ä¿ç•™åŸå§‹å†…å®¹ä»¥å®ç°æ— æŸé‡æ„
    
    12ç»´ç‰¹å¾ç»“æ„ï¼ˆå€Ÿé‰´æ—¶é—´é›†ç»´åº¦ç³»ç»Ÿï¼‰ï¼š
    
    [æ—¶é—´ç»´åº¦ 4ç»´] - æè¿°ä¿¡æ¯çš„æ—¶é—´å±æ€§
    1. inner_time: å†…åœ¨æ—¶é—´ï¼ˆåºåˆ—ä¸­çš„ç›¸å¯¹ä½ç½®ï¼Œä¸»è§‚æ—¶é—´ï¼‰
    2. outer_time: å¤–éƒ¨æ—¶é—´ï¼ˆç»å¯¹æ—¶é—´æˆ³ï¼Œå®¢è§‚æ—¶é—´ï¼‰
    3. time_flow: æ—¶é—´æµé€Ÿï¼ˆä¿¡æ¯çš„å˜åŒ–ç‡ï¼‰
    4. current_time: å½“å‰çŠ¶æ€æ—¶é—´
    
    [ç©ºé—´ç»´åº¦ 3ç»´] - æè¿°ä¿¡æ¯çš„ç©ºé—´å±æ€§
    5. spatial_x: Xåæ ‡ï¼ˆåºåˆ—ä½ç½®ï¼Œç‚¹ç»´åº¦ï¼‰
    6. spatial_y: Yåæ ‡ï¼ˆå†…å®¹å‡å€¼ï¼Œé¢ç»´åº¦ï¼‰
    7. spatial_z: Zåæ ‡ï¼ˆå†…å®¹æ–¹å·®ï¼Œç«‹ä½“ç»´åº¦ï¼‰
    
    [ç»“æ„ç»´åº¦ 4ç»´] - æè¿°ä¿¡æ¯çš„å†…åœ¨ç»“æ„
    8. density: ä¿¡æ¯å¯†åº¦ï¼ˆå†…å®¹ä¸°å¯Œåº¦ï¼Œéé›¶å…ƒç´ æ¯”ä¾‹ï¼‰
    9. connectivity: ä¿¡æ¯è¿æ¥åº¦ï¼ˆä¸å…¶ä»–ç²’å­çš„å…³è”ï¼‰
    10. stability: ä¿¡æ¯ç¨³å®šæ€§ï¼ˆç¡®å®šæ€§ï¼Œæ–¹å·®çš„å€’æ•°ï¼‰
    11. energy: ä¿¡æ¯èƒ½é‡ï¼ˆé‡è¦æ€§/æ´»è·ƒåº¦ï¼ŒL2èŒƒæ•°ï¼‰
    
    [ç»¼åˆæŒ‡æ ‡ 1ç»´]
    12. sif_value: Structure-Information-Functionå€¼ï¼ˆç»¼åˆè´¨é‡è¯„ä¼°ï¼‰
    """
    
    # === 12ç»´æ ¸å¿ƒç‰¹å¾ ===
    # æ—¶é—´ç»´åº¦ [4ç»´]
    inner_time: float      # å†…åœ¨æ—¶é—´ï¼ˆåºåˆ—ç´¢å¼•å½’ä¸€åŒ–åˆ°[0,1]ï¼‰
    outer_time: float      # å¤–éƒ¨æ—¶é—´ï¼ˆç»å¯¹æ—¶é—´æˆ³ï¼‰
    time_flow: float       # æ—¶é—´æµé€Ÿï¼ˆå˜åŒ–ç‡ï¼‰
    current_time: float    # å½“å‰çŠ¶æ€æ—¶é—´
    
    # ç©ºé—´ç»´åº¦ [3ç»´]
    spatial_x: float       # Xåæ ‡ï¼ˆåºåˆ—ä½ç½®å½’ä¸€åŒ–ï¼‰
    spatial_y: float       # Yåæ ‡ï¼ˆå†…å®¹å¹³å‡å€¼ï¼‰
    spatial_z: float       # Zåæ ‡ï¼ˆå†…å®¹æ–¹å·®ï¼Œåæ˜ ç«‹ä½“å¤æ‚åº¦ï¼‰
    
    # ç»“æ„ç»´åº¦ [4ç»´]
    density: float         # ä¿¡æ¯å¯†åº¦ï¼ˆéé›¶å…ƒç´ æ¯”ä¾‹ï¼‰
    connectivity: float    # è¿æ¥åº¦ï¼ˆä¸ç›¸é‚»ç²’å­çš„ç›¸ä¼¼åº¦ï¼‰
    stability: float       # ç¨³å®šæ€§ï¼ˆ1 / (1 + variance)ï¼‰
    energy: float          # èƒ½é‡ï¼ˆL2èŒƒæ•°å½’ä¸€åŒ–ï¼‰
    
    # ç»¼åˆæŒ‡æ ‡ [1ç»´]
    sif_value: float       # Structure-Information-Functionå€¼
    
    # === åŸå§‹å†…å®¹ï¼ˆç”¨äºæ— æŸé‡æ„ï¼‰===
    raw_content: torch.Tensor  # åŸå§‹æ•°æ®ç‰‡æ®µ
    sequence_index: int        # åœ¨åºåˆ—ä¸­çš„ç´¢å¼•ä½ç½®
    
    # === å¯é€‰å±æ€§ ===
    semantic_tag: Optional[str] = None  # è¯­ä¹‰æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
    metadata: Optional[Dict[str, Any]] = None  # å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    
    def to_vector(self) -> torch.Tensor:
        """
        è½¬æ¢ä¸º12ç»´ç‰¹å¾å‘é‡
        
        Returns:
            [12] ç»´åº¦çš„ç‰¹å¾å‘é‡
        """
        return torch.tensor([
            self.inner_time, self.outer_time, 
            self.time_flow, self.current_time,
            self.spatial_x, self.spatial_y, self.spatial_z,
            self.density, self.connectivity, 
            self.stability, self.energy,
            self.sif_value
        ], dtype=torch.float32)
    
    def get_sphere_coordinates(self) -> Tuple[float, float, float]:
        """
        è·å–çƒé¢åæ ‡è¡¨ç¤º
        
        ä½¿ç”¨çº¯æ•°å­¦å…¬å¼å°†12ç»´ç‰¹å¾æ˜ å°„åˆ°çƒé¢åæ ‡(r, Î¸, Ï†)
        
        Returns:
            (r, theta, phi) çƒé¢åæ ‡
        """
        # å¾„å‘rï¼šåæ˜ æŠ½è±¡å±‚æ¬¡ï¼ˆç¨³å®šæ€§å’Œèƒ½é‡çš„ç»¼åˆï¼‰
        r = 0.5 * self.stability + 0.5 * self.energy
        r = max(0.1, min(r, 1.0))  # æˆªæ–­åˆ°[0.1, 1.0]
        
        # æè§’Î¸ï¼šåæ˜ ç©ºé—´ä½ç½®ï¼ˆ0åˆ°Ï€ï¼‰
        theta = np.pi * (0.5 * self.spatial_x + 0.5 * np.tanh(self.spatial_y))
        theta = max(0, min(theta, np.pi))
        
        # æ–¹ä½è§’Ï†ï¼šåæ˜ æ—¶é—´å’Œå…³è”æ€§ï¼ˆ0åˆ°2Ï€ï¼‰
        phi = 2 * np.pi * (0.6 * self.inner_time + 0.4 * self.connectivity)
        phi = phi % (2 * np.pi)  # ç¡®ä¿åœ¨[0, 2Ï€]
        
        return (r, theta, phi)
    
    def __repr__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"InformationParticle(idx={self.sequence_index}, "
                f"sif={self.sif_value:.3f}, "
                f"energy={self.energy:.3f}, "
                f"stability={self.stability:.3f})")


@dataclass
class InformationGroup:
    """
    ä¿¡æ¯ç»„ - è¯­ä¹‰å®Œæ•´çš„ä¿¡æ¯å•å…ƒ
    
    ç”±å¤šä¸ªä¿¡æ¯ç²’å­èšåˆè€Œæˆï¼Œä»£è¡¨ä¸€ä¸ªè¯­ä¹‰å®Œæ•´çš„æ¦‚å¿µ
    """
    
    particles: List[InformationParticle]  # ç»„æˆæ­¤ç»„çš„ç²’å­åˆ—è¡¨
    group_id: int                          # ç»„ID
    
    # èšåˆç‰¹å¾ï¼ˆä»ç²’å­è®¡ç®—è€Œæ¥ï¼‰
    centroid_features: torch.Tensor = None  # è´¨å¿ƒç‰¹å¾ï¼ˆ12ç»´ï¼‰
    aggregated_content: torch.Tensor = None # èšåˆå†…å®¹
    
    # ç»„çº§åˆ«çš„å±æ€§
    group_sif: float = 0.0                 # ç»„çš„SIFå€¼
    group_stability: float = 0.0           # ç»„çš„ç¨³å®šæ€§
    group_size: int = 0                    # ç»„çš„å¤§å°
    
    def __post_init__(self):
        """åˆå§‹åŒ–åè®¡ç®—èšåˆç‰¹å¾"""
        if self.particles:
            self.group_size = len(self.particles)
            self._compute_aggregated_features()
    
    def _compute_aggregated_features(self):
        """è®¡ç®—èšåˆç‰¹å¾"""
        if not self.particles:
            return
        
        # è®¡ç®—è´¨å¿ƒï¼ˆæ‰€æœ‰ç²’å­12ç»´ç‰¹å¾çš„å¹³å‡ï¼‰
        particle_vectors = torch.stack([p.to_vector() for p in self.particles])
        self.centroid_features = particle_vectors.mean(dim=0)
        
        # èšåˆå†…å®¹ï¼ˆæ‹¼æ¥æ‰€æœ‰raw_contentï¼‰
        contents = [p.raw_content for p in self.particles]
        self.aggregated_content = torch.cat(contents, dim=0)
        
        # è®¡ç®—ç»„çº§åˆ«çš„SIFï¼ˆå¹³å‡ï¼‰
        self.group_sif = sum(p.sif_value for p in self.particles) / len(self.particles)
        
        # è®¡ç®—ç»„çº§åˆ«çš„ç¨³å®šæ€§ï¼ˆå¹³å‡ï¼‰
        self.group_stability = sum(p.stability for p in self.particles) / len(self.particles)
    
    def get_sphere_coordinates(self) -> Tuple[float, float, float]:
        """
        è·å–ç»„çš„çƒé¢åæ ‡ï¼ˆä½¿ç”¨è´¨å¿ƒï¼‰
        
        Returns:
            (r, theta, phi) çƒé¢åæ ‡
        """
        # ä½¿ç”¨è´¨å¿ƒç‰¹å¾è®¡ç®—
        stability = self.centroid_features[9].item()
        energy = self.centroid_features[10].item()
        spatial_x = self.centroid_features[4].item()
        spatial_y = self.centroid_features[5].item()
        inner_time = self.centroid_features[0].item()
        connectivity = self.centroid_features[8].item()
        
        # å¾„å‘
        r = 0.5 * stability + 0.5 * energy
        r = max(0.1, min(r, 1.0))
        
        # æè§’
        theta = np.pi * (0.5 * spatial_x + 0.5 * np.tanh(spatial_y))
        theta = max(0, min(theta, np.pi))
        
        # æ–¹ä½è§’
        phi = 2 * np.pi * (0.6 * inner_time + 0.4 * connectivity)
        phi = phi % (2 * np.pi)
        
        return (r, theta, phi)


class InformationParticleExtractor:
    """
    ä¿¡æ¯ç²’å­æå–å™¨ - çº¯è§„åˆ™æ–¹æ³•ï¼Œæ— ç¥ç»ç½‘ç»œ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å°†åŸå§‹æ•°æ®åºåˆ—åˆ†å‰²ä¸ºä¿¡æ¯ç²’å­
    2. ä¸ºæ¯ä¸ªç²’å­è®¡ç®—12ç»´ç‰¹å¾ï¼ˆçº¯æ•°å­¦ç»Ÿè®¡ï¼‰
    3. è®¡ç®—ç²’å­é—´çš„è¿æ¥åº¦
    4. è®¡ç®—SIFå€¼ï¼ˆStructure-Information-Functionï¼‰
    
    è®¾è®¡åŸåˆ™ï¼š
    - å®Œå…¨é€æ˜ï¼šæ‰€æœ‰è®¡ç®—éƒ½æ˜¯æ˜ç¡®çš„æ•°å­¦å…¬å¼
    - æ— æŸåˆ†å‰²ï¼šæ‰€æœ‰ç²’å­çš„raw_contentæ‹¼æ¥åç­‰äºåŸå§‹æ•°æ®
    - ç‹¬ç«‹æ€§ï¼šæ¯ä¸ªç²’å­éƒ½æ˜¯ç‹¬ç«‹çš„ä¿¡æ¯å•å…ƒ
    """
    
    def __init__(self, particle_size: int = 28, device: str = 'cpu'):
        """
        Args:
            particle_size: æ¯ä¸ªç²’å­åŒ…å«çš„æ•°æ®ç‚¹æ•°é‡ï¼ˆé»˜è®¤28ï¼Œé€‚åˆMNISTçš„28è¡Œï¼‰
            device: è®¡ç®—è®¾å¤‡
        """
        self.particle_size = particle_size
        self.device = device
        
        # SIFè®¡ç®—çš„æƒé‡ï¼ˆå¯è°ƒæ•´ï¼‰
        self.sif_weights = {
            'structure': 0.3,    # ç»“æ„æƒé‡
            'information': 0.4,  # ä¿¡æ¯æƒé‡
            'function': 0.3      # åŠŸèƒ½æƒé‡
        }
    
    def extract(self, data: torch.Tensor) -> List[InformationParticle]:
        """
        å°†æ•°æ®ç²’å­åŒ–
        
        æ•°å­¦åŸç†ï¼š
        1. å›ºå®šçª—å£åˆ†å‰²ï¼ˆä¿è¯æ— æŸï¼‰
        2. æ¯ä¸ªç²’å­è®¡ç®—12ç»´ç‰¹å¾ï¼ˆçº¯ç»Ÿè®¡æ–¹æ³•ï¼‰
        3. è®¡ç®—ç²’å­é—´è¿æ¥åº¦ï¼ˆç›¸ä¼¼åº¦ï¼‰
        4. è®¡ç®—SIFå€¼ï¼ˆç»¼åˆè¯„ä¼°ï¼‰
        
        Args:
            data: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º [seq_len, feature_dim] æˆ– [batch, seq_len, feature_dim]
        
        Returns:
            ä¿¡æ¯ç²’å­åˆ—è¡¨
        """
        # å¤„ç†æ‰¹æ¬¡ç»´åº¦
        if data.dim() == 3:
            # [batch, seq_len, feature_dim] -> [seq_len, feature_dim]
            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            data = data[0]
        
        # ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if data.device.type != self.device:
            data = data.to(self.device)
        
        seq_len = data.shape[0]
        particles = []
        
        # å›ºå®šçª—å£åˆ†å‰²
        num_particles = math.ceil(seq_len / self.particle_size)
        
        print(f"\nğŸ”¬ ä¿¡æ¯ç²’å­åŒ–å¼€å§‹...")
        print(f"   è¾“å…¥æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"   ç²’å­å¤§å°: {self.particle_size}")
        print(f"   é¢„è®¡ç²’å­æ•°: {num_particles}")
        
        for i in range(num_particles):
            start_idx = i * self.particle_size
            end_idx = min(start_idx + self.particle_size, seq_len)
            
            # æå–åŸå§‹å†…å®¹
            raw_content = data[start_idx:end_idx].clone()
            
            # è®¡ç®—12ç»´ç‰¹å¾ï¼ˆçº¯æ•°å­¦æ–¹æ³•ï¼‰
            particle = self._compute_particle_features(
                raw_content=raw_content,
                sequence_index=i,
                total_particles=num_particles
            )
            
            particles.append(particle)
        
        # è®¡ç®—ç²’å­é—´çš„connectivityï¼ˆç¬¬äºŒéï¼‰
        self._compute_connectivity(particles)
        
        print(f"âœ… ç²’å­åŒ–å®Œæˆï¼Œç”Ÿæˆ {len(particles)} ä¸ªä¿¡æ¯ç²’å­")
        print(f"   å¹³å‡SIFå€¼: {sum(p.sif_value for p in particles) / len(particles):.4f}")
        print(f"   å¹³å‡èƒ½é‡: {sum(p.energy for p in particles) / len(particles):.4f}")
        
        return particles
    
    def _compute_particle_features(
        self, 
        raw_content: torch.Tensor,
        sequence_index: int,
        total_particles: int
    ) -> InformationParticle:
        """
        çº¯æ•°å­¦æ–¹æ³•è®¡ç®—12ç»´ç‰¹å¾
        
        æ¯ä¸ªç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„æ•°å­¦å®šä¹‰å’Œç‰©ç†æ„ä¹‰
        
        Args:
            raw_content: åŸå§‹æ•°æ®ç‰‡æ®µ [chunk_size, feature_dim]
            sequence_index: åºåˆ—ç´¢å¼•
            total_particles: æ€»ç²’å­æ•°
        
        Returns:
            InformationParticle
        """
        # === æ—¶é—´ç»´åº¦ [4ç»´] ===
        # 1. å†…åœ¨æ—¶é—´ï¼šåœ¨åºåˆ—ä¸­çš„ç›¸å¯¹ä½ç½®ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]ï¼‰
        inner_time = sequence_index / max(total_particles - 1, 1)
        
        # 2. å¤–éƒ¨æ—¶é—´ï¼šç»å¯¹æ—¶é—´æˆ³ï¼ˆå½“å‰æ—¶é—´ï¼‰
        outer_time = time.time()
        
        # 3. æ—¶é—´æµé€Ÿï¼šæš‚æ—¶è®¾ä¸º1.0ï¼ˆå¯ä»¥åç»­æ ¹æ®å˜åŒ–ç‡è®¡ç®—ï¼‰
        time_flow = 1.0
        
        # 4. å½“å‰çŠ¶æ€æ—¶é—´ï¼šä¸å¤–éƒ¨æ—¶é—´ç›¸åŒ
        current_time = outer_time
        
        # === ç©ºé—´ç»´åº¦ [3ç»´] ===
        # 5. spatial_x: åºåˆ—ä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰
        spatial_x = inner_time  # ä¸inner_timeç›¸åŒï¼Œè¡¨ç¤ºåœ¨åºåˆ—ä¸­çš„ä½ç½®
        
        # 6. spatial_y: å†…å®¹å‡å€¼ï¼ˆåæ˜ å†…å®¹çš„å¹³å‡æ°´å¹³ï¼‰
        spatial_y = raw_content.mean().item()
        
        # 7. spatial_z: å†…å®¹æ–¹å·®ï¼ˆåæ˜ å†…å®¹çš„å¤æ‚åº¦/ç«‹ä½“æ€§ï¼‰
        spatial_z = raw_content.std().item()
        
        # === ç»“æ„ç»´åº¦ [4ç»´] ===
        # 8. density: ä¿¡æ¯å¯†åº¦ï¼ˆéé›¶å…ƒç´ çš„æ¯”ä¾‹ï¼‰
        density = (raw_content != 0).float().mean().item()
        
        # 9. connectivity: è¿æ¥åº¦ï¼ˆå…ˆè®¾ä¸º0ï¼Œåç»­è®¡ç®—ï¼‰
        connectivity = 0.0  # éœ€è¦åœ¨æ‰€æœ‰ç²’å­åˆ›å»ºåè®¡ç®—
        
        # 10. stability: ç¨³å®šæ€§ï¼ˆæ–¹å·®çš„å€’æ•°ï¼Œæ–¹å·®å°åˆ™ç¨³å®šæ€§é«˜ï¼‰
        variance = raw_content.var().item()
        stability = 1.0 / (1.0 + variance)  # åŠ 1é¿å…é™¤é›¶
        
        # 11. energy: èƒ½é‡ï¼ˆL2èŒƒæ•°ï¼Œå½’ä¸€åŒ–åˆ°æ¯ä¸ªå…ƒç´ ï¼‰
        energy = raw_content.norm().item() / max(raw_content.numel(), 1)
        
        # === ç»¼åˆæŒ‡æ ‡ [1ç»´] ===
        # 12. sif_value: æš‚æ—¶è®¡ç®—ï¼ˆconnectivityä¸º0ï¼‰ï¼Œåç»­æ›´æ–°
        sif_value = self._compute_sif(
            density=density,
            connectivity=connectivity,
            stability=stability,
            energy=energy,
            spatial_z=spatial_z
        )
        
        return InformationParticle(
            inner_time=inner_time,
            outer_time=outer_time,
            time_flow=time_flow,
            current_time=current_time,
            spatial_x=spatial_x,
            spatial_y=spatial_y,
            spatial_z=spatial_z,
            density=density,
            connectivity=connectivity,
            stability=stability,
            energy=energy,
            sif_value=sif_value,
            raw_content=raw_content,
            sequence_index=sequence_index
        )
    
    def _compute_sif(
        self, 
        density: float,
        connectivity: float,
        stability: float,
        energy: float,
        spatial_z: float
    ) -> float:
        """
        è®¡ç®—SIFå€¼ï¼ˆStructure-Information-Functionï¼‰
        
        æ•°å­¦å®šä¹‰ï¼š
        SIF = Î±Â·Structure + Î²Â·Information + Î³Â·Function
        
        å…¶ä¸­ï¼š
        - Structure: ç»“æ„å®Œæ•´æ€§ï¼ˆåŸºäºç©ºé—´æ–¹å·®å’Œç¨³å®šæ€§ï¼‰
        - Information: ä¿¡æ¯ä¸°å¯Œåº¦ï¼ˆåŸºäºå¯†åº¦å’Œèƒ½é‡ï¼‰
        - Function: åŠŸèƒ½æ€§ï¼ˆåŸºäºè¿æ¥åº¦ï¼‰
        - Î±, Î², Î³ ä¸ºæƒé‡ï¼Œæ»¡è¶³ Î± + Î² + Î³ = 1
        
        Args:
            density: ä¿¡æ¯å¯†åº¦
            connectivity: è¿æ¥åº¦
            stability: ç¨³å®šæ€§
            energy: èƒ½é‡
            spatial_z: ç©ºé—´æ–¹å·®
        
        Returns:
            SIFå€¼ï¼ŒèŒƒå›´[0, 1]
        """
        # Structure: åŸºäºç©ºé—´æ–¹å·®å’Œç¨³å®šæ€§
        # æ–¹å·®å¤§ â†’ ç»“æ„å¤æ‚ï¼Œç¨³å®šæ€§é«˜ â†’ ç»“æ„å¥½
        structure_score = 0.5 * min(spatial_z, 1.0) + 0.5 * stability
        
        # Information: åŸºäºå¯†åº¦å’Œèƒ½é‡
        # å¯†åº¦é«˜ã€èƒ½é‡é«˜ â†’ ä¿¡æ¯ä¸°å¯Œ
        information_score = 0.6 * density + 0.4 * min(energy, 1.0)
        
        # Function: åŸºäºè¿æ¥åº¦
        # è¿æ¥åº¦é«˜ â†’ åŠŸèƒ½æ€§å¼º
        function_score = connectivity
        
        # ç»¼åˆSIFå€¼ï¼ˆä½¿ç”¨é…ç½®çš„æƒé‡ï¼‰
        sif = (self.sif_weights['structure'] * structure_score +
               self.sif_weights['information'] * information_score +
               self.sif_weights['function'] * function_score)
        
        # ç¡®ä¿åœ¨[0, 1]èŒƒå›´å†…
        return max(0.0, min(sif, 1.0))
    
    def _compute_connectivity(self, particles: List[InformationParticle]):
        """
        è®¡ç®—ç²’å­é—´çš„è¿æ¥åº¦ï¼ˆç›¸ä¼¼åº¦ï¼‰
        
        ç­–ç•¥ï¼š
        - ç¬¬ä¸€ä¸ªç²’å­ï¼šä¸ä¸‹ä¸€ä¸ªç²’å­çš„ç›¸ä¼¼åº¦
        - ä¸­é—´ç²’å­ï¼šä¸å‰åç²’å­çš„å¹³å‡ç›¸ä¼¼åº¦
        - æœ€åä¸€ä¸ªç²’å­ï¼šä¸å‰ä¸€ä¸ªç²’å­çš„ç›¸ä¼¼åº¦
        
        Args:
            particles: ç²’å­åˆ—è¡¨ï¼ˆä¼šè¢«åŸåœ°ä¿®æ”¹ï¼‰
        """
        if len(particles) <= 1:
            return
        
        print(f"   è®¡ç®—ç²’å­è¿æ¥åº¦...")
        
        for i in range(len(particles)):
            if i == 0:
                # ç¬¬ä¸€ä¸ªç²’å­ï¼šåªä¸ä¸‹ä¸€ä¸ªæ¯”è¾ƒ
                sim = self._cosine_similarity(
                    particles[i].raw_content,
                    particles[i+1].raw_content
                )
                particles[i].connectivity = sim
                
            elif i == len(particles) - 1:
                # æœ€åä¸€ä¸ªç²’å­ï¼šåªä¸å‰ä¸€ä¸ªæ¯”è¾ƒ
                sim = self._cosine_similarity(
                    particles[i].raw_content,
                    particles[i-1].raw_content
                )
                particles[i].connectivity = sim
                
            else:
                # ä¸­é—´ç²’å­ï¼šä¸å‰åçš„å¹³å‡ç›¸ä¼¼åº¦
                sim_prev = self._cosine_similarity(
                    particles[i].raw_content,
                    particles[i-1].raw_content
                )
                sim_next = self._cosine_similarity(
                    particles[i].raw_content,
                    particles[i+1].raw_content
                )
                particles[i].connectivity = (sim_prev + sim_next) / 2
            
            # é‡æ–°è®¡ç®—SIFï¼ˆç°åœ¨åŒ…å«connectivityï¼‰
            particles[i].sif_value = self._compute_sif(
                density=particles[i].density,
                connectivity=particles[i].connectivity,
                stability=particles[i].stability,
                energy=particles[i].energy,
                spatial_z=particles[i].spatial_z
            )
    
    @staticmethod
    def _cosine_similarity(a: torch.Tensor, b: torch.Tensor) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå¼ é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            a, b: è¾“å…¥å¼ é‡
        
        Returns:
            ä½™å¼¦ç›¸ä¼¼åº¦ï¼ŒèŒƒå›´[-1, 1]ï¼Œå½’ä¸€åŒ–åˆ°[0, 1]
        """
        # å±•å¹³ä¸º1D
        a_flat = a.flatten()
        b_flat = b.flatten()
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        sim = F.cosine_similarity(a_flat.unsqueeze(0), b_flat.unsqueeze(0), dim=1).item()
        
        # å½’ä¸€åŒ–åˆ°[0, 1]
        sim = (sim + 1.0) / 2.0
        
        return sim


class InformationGroupBuilder:
    """
    ä¿¡æ¯ç»„æ„å»ºå™¨ - å°†ç²’å­èšåˆæˆè¯­ä¹‰å•å…ƒ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŸºäºç›¸ä¼¼åº¦èšç±»ä¿¡æ¯ç²’å­
    2. å½¢æˆè¯­ä¹‰å®Œæ•´çš„ä¿¡æ¯ç»„
    3. çº¯è§„åˆ™æ–¹æ³•ï¼ˆæ— ç¥ç»ç½‘ç»œï¼‰
    """
    
    def __init__(
        self, 
        similarity_threshold: float = 0.7,
        max_group_size: int = 10
    ):
        """
        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé«˜äºæ­¤å€¼çš„ç²’å­ä¼šè¢«èšåˆï¼‰
            max_group_size: æœ€å¤§ç»„å¤§å°
        """
        self.similarity_threshold = similarity_threshold
        self.max_group_size = max_group_size
    
    def build_groups(
        self, 
        particles: List[InformationParticle]
    ) -> List[InformationGroup]:
        """
        æ„å»ºä¿¡æ¯ç»„
        
        ç­–ç•¥ï¼š
        - åŸºäºè¿æ¥åº¦çš„è´ªå¿ƒèšç±»
        - ç›¸é‚»ä¸”ç›¸ä¼¼çš„ç²’å­èšåˆä¸ºä¸€ç»„
        
        Args:
            particles: ä¿¡æ¯ç²’å­åˆ—è¡¨
        
        Returns:
            ä¿¡æ¯ç»„åˆ—è¡¨
        """
        if not particles:
            return []
        
        print(f"\nğŸ”— ä¿¡æ¯ç»„æ„å»ºå¼€å§‹...")
        print(f"   ç²’å­æ•°é‡: {len(particles)}")
        print(f"   ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        
        groups = []
        used = set()
        
        for i, particle in enumerate(particles):
            if i in used:
                continue
            
            # åˆ›å»ºæ–°ç»„
            group_particles = [particle]
            used.add(i)
            
            # æŸ¥æ‰¾ç›¸é‚»çš„ç›¸ä¼¼ç²’å­
            for j in range(i + 1, min(i + self.max_group_size, len(particles))):
                if j in used:
                    continue
                
                # æ£€æŸ¥ä¸ç»„ä¸­æ‰€æœ‰ç²’å­çš„å¹³å‡ç›¸ä¼¼åº¦
                avg_similarity = particles[j].connectivity
                
                if avg_similarity > self.similarity_threshold:
                    group_particles.append(particles[j])
                    used.add(j)
                else:
                    break  # ä¸å†è¿ç»­ç›¸ä¼¼ï¼Œåœæ­¢
            
            # åˆ›å»ºä¿¡æ¯ç»„
            group = InformationGroup(
                particles=group_particles,
                group_id=len(groups)
            )
            groups.append(group)
        
        print(f"âœ… ä¿¡æ¯ç»„æ„å»ºå®Œæˆï¼Œç”Ÿæˆ {len(groups)} ä¸ªä¿¡æ¯ç»„")
        print(f"   å¹³å‡ç»„å¤§å°: {sum(g.group_size for g in groups) / len(groups):.2f}")
        print(f"   å¹³å‡ç»„SIF: {sum(g.group_sif for g in groups) / len(groups):.4f}")
        
        return groups


class LosslessReconstructor:
    """
    æ— æŸé‡æ„å™¨ - ä»ä¿¡æ¯ç²’å­å®Œç¾é‡æ„åŸå§‹æ•°æ®
    
    æ ¸å¿ƒåŸç†ï¼š
    - ç›´æ¥æå–å’Œæ‹¼æ¥ç²’å­çš„raw_content
    - æŒ‰sequence_indexæ’åºä¿è¯é¡ºåº
    - å®ç°MSE=0çš„å®Œç¾é‡æ„
    """
    
    def __init__(self):
        pass
    
    def reconstruct_from_particles(
        self, 
        particles: List[InformationParticle]
    ) -> torch.Tensor:
        """
        ä»ä¿¡æ¯ç²’å­é‡æ„åŸå§‹æ•°æ®
        
        Args:
            particles: ä¿¡æ¯ç²’å­åˆ—è¡¨
        
        Returns:
            é‡æ„çš„æ•°æ®ï¼Œå½¢çŠ¶ä¸åŸå§‹è¾“å…¥ç›¸åŒ
        """
        if not particles:
            return None
        
        print(f"\nğŸ”„ æ— æŸé‡æ„å¼€å§‹...")
        print(f"   ç²’å­æ•°é‡: {len(particles)}")
        
        # æŒ‰sequence_indexæ’åº
        sorted_particles = sorted(particles, key=lambda p: p.sequence_index)
        
        # æ‹¼æ¥raw_content
        reconstructed_segments = [p.raw_content for p in sorted_particles]
        reconstructed = torch.cat(reconstructed_segments, dim=0)
        
        print(f"âœ… é‡æ„å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {reconstructed.shape}")
        
        return reconstructed
    
    def reconstruct_from_groups(
        self, 
        groups: List[InformationGroup]
    ) -> torch.Tensor:
        """
        ä»ä¿¡æ¯ç»„é‡æ„åŸå§‹æ•°æ®
        
        Args:
            groups: ä¿¡æ¯ç»„åˆ—è¡¨
        
        Returns:
            é‡æ„çš„æ•°æ®
        """
        if not groups:
            return None
        
        # æå–æ‰€æœ‰ç²’å­
        all_particles = []
        for group in groups:
            all_particles.extend(group.particles)
        
        # ä½¿ç”¨ç²’å­é‡æ„
        return self.reconstruct_from_particles(all_particles)


class PureMathematicalSphereMapper:
    """
    çº¯æ•°å­¦çš„çƒé¢æ˜ å°„å™¨ - æ— ç¥ç»ç½‘ç»œ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å°†ä¿¡æ¯ç²’å­æ˜ å°„åˆ°çƒé¢åæ ‡(r, Î¸, Ï†)
    2. å°†ä¿¡æ¯ç»„æ˜ å°„åˆ°çƒé¢åæ ‡
    3. ä½¿ç”¨æ˜ç¡®çš„æ•°å­¦å…¬å¼ï¼ˆå®Œå…¨é€æ˜ï¼‰
    
    æ•°å­¦å…¬å¼ï¼š
    - r (å¾„å‘): åæ˜ æŠ½è±¡å±‚æ¬¡ï¼ŒåŸºäºç¨³å®šæ€§å’Œèƒ½é‡
    - Î¸ (æè§’): åæ˜ ç©ºé—´ä½ç½®ï¼ŒåŸºäºspatial_xå’Œspatial_y
    - Ï† (æ–¹ä½è§’): åæ˜ æ—¶é—´å’Œå…³è”æ€§ï¼ŒåŸºäºinner_timeå’Œconnectivity
    """
    
    def __init__(self):
        pass
    
    def map_particle_to_sphere(
        self, 
        particle: InformationParticle
    ) -> Dict[str, Any]:
        """
        å°†ä¿¡æ¯ç²’å­æ˜ å°„åˆ°çƒé¢åæ ‡
        
        Args:
            particle: ä¿¡æ¯ç²’å­
        
        Returns:
            åŒ…å«çƒé¢åæ ‡å’Œç¬›å¡å°”åæ ‡çš„å­—å…¸
        """
        # è·å–çƒé¢åæ ‡ï¼ˆä½¿ç”¨ç²’å­çš„å†…ç½®æ–¹æ³•ï¼‰
        r, theta, phi = particle.get_sphere_coordinates()
        
        # è½¬æ¢ä¸ºç¬›å¡å°”åæ ‡
        x = r * np.sin(theta) * np.cos(phi)
        y = r * np.sin(theta) * np.sin(phi)
        z = r * np.cos(theta)
        
        return {
            'spherical': {'r': r, 'theta': theta, 'phi': phi},
            'cartesian': {'x': x, 'y': y, 'z': z},
            'particle_index': particle.sequence_index,
            'sif_value': particle.sif_value
        }
    
    def map_group_to_sphere(
        self, 
        group: InformationGroup
    ) -> Dict[str, Any]:
        """
        å°†ä¿¡æ¯ç»„æ˜ å°„åˆ°çƒé¢åæ ‡
        
        Args:
            group: ä¿¡æ¯ç»„
        
        Returns:
            åŒ…å«çƒé¢åæ ‡å’Œç¬›å¡å°”åæ ‡çš„å­—å…¸
        """
        # è·å–çƒé¢åæ ‡ï¼ˆä½¿ç”¨ç»„çš„å†…ç½®æ–¹æ³•ï¼‰
        r, theta, phi = group.get_sphere_coordinates()
        
        # è½¬æ¢ä¸ºç¬›å¡å°”åæ ‡
        x = r * np.sin(theta) * np.cos(phi)
        y = r * np.sin(theta) * np.sin(phi)
        z = r * np.cos(theta)
        
        return {
            'spherical': {'r': r, 'theta': theta, 'phi': phi},
            'cartesian': {'x': x, 'y': y, 'z': z},
            'group_id': group.group_id,
            'group_size': group.group_size,
            'group_sif': group.group_sif
        }
    
    def map_all_particles(
        self, 
        particles: List[InformationParticle]
    ) -> List[Dict[str, Any]]:
        """
        æ˜ å°„æ‰€æœ‰ç²’å­åˆ°çƒé¢
        
        Args:
            particles: ç²’å­åˆ—è¡¨
        
        Returns:
            çƒé¢åæ ‡åˆ—è¡¨
        """
        return [self.map_particle_to_sphere(p) for p in particles]
    
    def map_all_groups(
        self, 
        groups: List[InformationGroup]
    ) -> List[Dict[str, Any]]:
        """
        æ˜ å°„æ‰€æœ‰ç»„åˆ°çƒé¢
        
        Args:
            groups: ç»„åˆ—è¡¨
        
        Returns:
            çƒé¢åæ ‡åˆ—è¡¨
        """
        return [self.map_group_to_sphere(g) for g in groups]


# ============================================
# æµ‹è¯•å’ŒéªŒè¯å‡½æ•°
# ============================================

def test_information_particle_system():
    """
    æµ‹è¯•ä¿¡æ¯ç²’å­ç³»ç»Ÿçš„å®Œæ•´æµç¨‹
    """
    print("="*70)
    print("  ä¿¡æ¯ç²’å­ç³»ç»Ÿæµ‹è¯•")
    print("  Information Particle System Test")
    print("="*70)
    
    # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\nğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®...")
    test_data = torch.randn(28, 28)  # ç±»ä¼¼MNISTçš„28x28æ•°æ®
    print(f"   æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    # 2. ç²’å­åŒ–
    print("\n" + "="*70)
    extractor = InformationParticleExtractor(particle_size=28)
    particles = extractor.extract(test_data)
    
    # 3. æ„å»ºä¿¡æ¯ç»„
    print("\n" + "="*70)
    group_builder = InformationGroupBuilder(similarity_threshold=0.5)
    groups = group_builder.build_groups(particles)
    
    # 4. çƒé¢æ˜ å°„
    print("\n" + "="*70)
    print("\nğŸŒ çƒé¢æ˜ å°„...")
    sphere_mapper = PureMathematicalSphereMapper()
    particle_coords = sphere_mapper.map_all_particles(particles)
    group_coords = sphere_mapper.map_all_groups(groups)
    
    print(f"âœ… æ˜ å°„å®Œæˆ")
    print(f"   ç²’å­åæ ‡æ•°é‡: {len(particle_coords)}")
    print(f"   ç»„åæ ‡æ•°é‡: {len(group_coords)}")
    
    # æ‰“å°ç¬¬ä¸€ä¸ªç²’å­çš„åæ ‡ç¤ºä¾‹
    if particle_coords:
        coord = particle_coords[0]
        print(f"\n   ç¤ºä¾‹ç²’å­åæ ‡:")
        print(f"   - çƒé¢: r={coord['spherical']['r']:.3f}, "
              f"Î¸={coord['spherical']['theta']:.3f}, "
              f"Ï†={coord['spherical']['phi']:.3f}")
        print(f"   - ç¬›å¡å°”: x={coord['cartesian']['x']:.3f}, "
              f"y={coord['cartesian']['y']:.3f}, "
              f"z={coord['cartesian']['z']:.3f}")
    
    # 5. æ— æŸé‡æ„
    print("\n" + "="*70)
    reconstructor = LosslessReconstructor()
    reconstructed = reconstructor.reconstruct_from_particles(particles)
    
    # 6. éªŒè¯æ— æŸæ€§
    print("\n" + "="*70)
    print("\nğŸ” éªŒè¯é‡æ„è´¨é‡...")
    mse = F.mse_loss(reconstructed, test_data).item()
    cos_sim = F.cosine_similarity(
        reconstructed.flatten(), 
        test_data.flatten(), 
        dim=0
    ).item()
    
    print(f"âœ… é‡æ„éªŒè¯:")
    print(f"   MSE: {mse:.10f}")
    print(f"   Cosine Similarity: {cos_sim:.10f}")
    
    if mse < 1e-6:
        print(f"   âœ… å®Œç¾é‡æ„ï¼ï¼ˆMSE â‰ˆ 0ï¼‰")
    else:
        print(f"   âš ï¸  é‡æ„æœ‰è¯¯å·®")
    
    print("\n" + "="*70)
    print("  æµ‹è¯•å®Œæˆï¼")
    print("="*70)
    
    return {
        'particles': particles,
        'groups': groups,
        'particle_coords': particle_coords,
        'group_coords': group_coords,
        'reconstructed': reconstructed,
        'mse': mse,
        'cosine_similarity': cos_sim
    }


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    test_information_particle_system()

